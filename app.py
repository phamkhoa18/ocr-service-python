"""
OCR Service Backend - Chuy√™n x·ª≠ l√Ω OCR ti·∫øng Vi·ªát
S·ª≠ d·ª•ng PaddleOCR - th∆∞ vi·ªán OCR t·ªët nh·∫•t cho ti·∫øng Vi·ªát
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
import os
import io
import base64
import time
from datetime import datetime
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
import cv2
import re  # ƒê·ªÉ check HTML tags
import requests  # ƒê·ªÉ g·ªçi Text Correction API
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Import OCR
from paddleocr import PaddleOCR

# Import Text/HTML utility functions
from text_html_utils import extract_text_from_html, text_to_html_paragraphs, text_to_html_paragraphs_with_alignment

# Text Correction API endpoint (load from .env, default to localhost:5001)
TEXT_CORRECTION_API_URL = os.getenv('TEXT_CORRECTION_API_URL', 'http://localhost:5001/correct')
TEXT_CORRECTION_AVAILABLE = True  # Lu√¥n available v√¨ d√πng API

def correct_vietnamese_text(text, use_correction=True, use_gpu=False):
    """
    G·ªçi API Text Correction ƒë·ªÉ ch·ªânh s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát
    API endpoint: http://localhost:5001/correct
    G·ªåI M·ªòT L·∫¶N cho to√†n b·ªô text (kh√¥ng chia nh·ªè) - NHANH v√† CHU·∫®N
    GPT-4o-mini s·∫Ω t·ª± ƒë·ªông gi·ªØ nguy√™n format xu·ªëng d√≤ng v√† spacing
    """
    if not use_correction or not text or not text.strip():
        return text
    
    try:
        # G·ªçi API m·ªôt l·∫ßn cho to√†n b·ªô text - NHANH v√† CHU·∫®N
        response = requests.post(
            TEXT_CORRECTION_API_URL,
            json={'text': text},
            timeout=120  # Timeout 120 gi√¢y cho text d√†i
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                corrected_text = result.get('corrected_text', text)
                return corrected_text
            else:
                # N·∫øu API l·ªói, gi·ªØ nguy√™n text g·ªëc
                print(f"‚ö†Ô∏è  API tr·∫£ v·ªÅ l·ªói: {result.get('error', 'Unknown error')}")
                return text
        else:
            # N·∫øu request failed, gi·ªØ nguy√™n text g·ªëc
            print(f"‚ö†Ô∏è  API request failed v·ªõi status code: {response.status_code}")
            return text
            
    except requests.exceptions.ConnectionError:
        print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Text Correction API ({TEXT_CORRECTION_API_URL})")
        print("üí° ƒê·∫£m b·∫£o API server ƒëang ch·∫°y: cd ocr-protonx && python app.py")
        return text
    except requests.exceptions.Timeout:
        print("‚ö†Ô∏è  API timeout (text qu√° d√†i ho·∫∑c server ch·∫≠m), gi·ªØ nguy√™n text g·ªëc")
        return text
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi g·ªçi Text Correction API: {str(e)}")
        return text

print("\n" + "="*60)
print("üì° Text Correction: S·ª≠ d·ª•ng API")
print("="*60)
print(f"‚Üí API endpoint: {TEXT_CORRECTION_API_URL}")
print("‚Üí Sau khi PaddleOCR xong ‚Üí G·ªçi API ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát")
print("="*60 + "\n")

app = Flask(__name__)
CORS(app)

# Configuration
UPLOAD_FOLDER = 'uploads'
# H·ªó tr·ª£ nhi·ªÅu format PDF v√† image
ALLOWED_EXTENSIONS = {
    # PDF formats
    'pdf',
    # Image formats
    'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp', 'tiff', 'tif',
    'jfif', 'pjpeg', 'pjp', 'svg', 'ico', 'heic', 'heif'
}
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB

os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Initialize PaddleOCR v·ªõi config t·ªëi ∆∞u cho ti·∫øng Vi·ªát - ƒê·∫¢M B·∫¢O KH√îNG M·∫§T CH·ªÆ
print("ƒêang kh·ªüi t·∫°o PaddleOCR cho ti·∫øng Vi·ªát...")
ocr_engine = PaddleOCR(
    use_angle_cls=True,  # S·ª≠ d·ª•ng g√≥c ƒë·ªô classification
    lang='vi',  # Ti·∫øng Vi·ªát
    use_gpu=False,  # Set True n·∫øu c√≥ GPU
    show_log=False,
    # Config ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng m·∫•t ch·ªØ
    det_db_thresh=0.3,  # Lower threshold ƒë·ªÉ detect nhi·ªÅu text h∆°n
    det_db_box_thresh=0.5,  # Lower ƒë·ªÉ kh√¥ng b·ªè s√≥t
    rec_batch_num=6,  # Batch size ƒë·ªÉ x·ª≠ l√Ω t·ªët h∆°n
    max_text_length=500  # Cho ph√©p text d√†i h∆°n
)
print("‚úÖ PaddleOCR ƒë√£ s·∫µn s√†ng v·ªõi config t·ªëi ∆∞u!")

def allowed_file(filename):
    """Check if file extension is allowed"""
    if not filename or '.' not in filename:
        return False
    ext = filename.rsplit('.', 1)[1].lower()
    return ext in ALLOWED_EXTENSIONS

def is_pdf_file(filename, file_buffer):
    """Check if file is PDF by content, not just extension"""
    try:
        # Check extension first (including cases where filename might be None or empty)
        if filename:
            filename_lower = filename.lower()
            if filename_lower.endswith('.pdf') or 'pdf' in filename_lower:
                # Verify by content too
                file_buffer.seek(0)
                header = file_buffer.read(4)
                file_buffer.seek(0)
                if header.startswith(b'%PDF'):
                    return True
        
        # Check magic bytes (PDF starts with %PDF) - primary check
        file_buffer.seek(0)
        # Read more bytes to be sure (PDF header can have whitespace)
        header = file_buffer.read(1024)
        file_buffer.seek(0)
        
        # Check for PDF magic bytes (can have whitespace before %PDF)
        if b'%PDF' in header[:1024]:
            return True
            
        # Also check for PDF in first bytes (sometimes Chrome adds data)
        if header.startswith(b'%PDF') or header.strip().startswith(b'%PDF'):
            return True
            
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Error checking PDF: {str(e)}")
        # Fallback: if filename suggests PDF, trust it
        if filename and filename.lower().endswith('.pdf'):
            return True
        return False

def is_image_file(filename, file_buffer):
    """Check if file is image by trying to open with PIL"""
    try:
        # First try to open with PIL (works for most formats)
        file_buffer.seek(0)
        buffer_copy = file_buffer.read()
        file_buffer.seek(0)
        
        # Try to open with PIL
        try:
            img = Image.open(io.BytesIO(buffer_copy))
            img.verify()  # Verify it's a valid image
            return True
        except:
            pass
        
        # Check extension as fallback
        if filename:
            ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else ''
            image_exts = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp', 'tiff', 'tif', 'jfif', 'pjpeg', 'pjp', 'ico', 'heic', 'heif'}
            if ext in image_exts:
                # Try again with format hint
                try:
                    file_buffer.seek(0)
                    img = Image.open(io.BytesIO(buffer_copy))
                    img.verify()
                    return True
                except:
                    pass
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Error checking image: {str(e)}")
        return False

def preprocess_image_for_ocr(image):
    """
    Preprocess image ƒë·ªÉ t·ªëi ∆∞u OCR cho ti·∫øng Vi·ªát - KH√îNG L√ÄM M·∫§T CH·ªÆ
    Preprocessing nh·∫π ƒë·ªÉ kh√¥ng l√†m m·∫•t th√¥ng tin text
    """
    try:
        # ƒê·∫£m b·∫£o image l√† RGB mode
        if image.mode != 'RGB':
            if image.mode == 'RGBA':
                # T·∫°o background tr·∫Øng cho RGBA
                rgb_image = Image.new('RGB', image.size, (255, 255, 255))
                rgb_image.paste(image, mask=image.split()[3] if image.mode == 'RGBA' else None)
                image = rgb_image
            else:
                image = image.convert('RGB')
        
        # Convert PIL to OpenCV format
        img_array = np.array(image)
        
        # ƒê·∫£m b·∫£o l√† uint8
        if img_array.dtype != np.uint8:
            img_array = img_array.astype(np.uint8)
        
        # GI·ªÆ NGUY√äN ·∫£nh g·ªëc n·∫øu ƒë√£ t·ªët - kh√¥ng preprocessing qu√° m·∫°nh
        # V√¨ preprocessing c√≥ th·ªÉ l√†m m·∫•t ch·ªØ ho·∫∑c l√†m sai text
        
        # Ch·ªâ enhance contrast nh·∫π n·∫øu c·∫ßn
        if len(img_array.shape) == 3:
            # Gi·ªØ color - kh√¥ng convert sang grayscale (c√≥ th·ªÉ m·∫•t th√¥ng tin)
            img_processed = img_array.copy()
            # Enhance contrast nh·∫π
            img_processed = cv2.convertScaleAbs(img_processed, alpha=1.2, beta=5)
        else:
            # Grayscale - enhance nh·∫π
            img_processed = cv2.convertScaleAbs(img_array, alpha=1.3, beta=5)
        
        # Convert back to PIL
        if len(img_processed.shape) == 2:
            return Image.fromarray(img_processed, mode='L')
        elif len(img_processed.shape) == 3:
            return Image.fromarray(cv2.cvtColor(img_processed, cv2.COLOR_BGR2RGB))
        else:
            return image  # Return original n·∫øu c√≥ v·∫•n ƒë·ªÅ
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi preprocess image: {str(e)}, gi·ªØ nguy√™n image g·ªëc")
        return image  # Return original n·∫øu c√≥ l·ªói

def extract_text_from_pdf(file_buffer):
    """
    Extract text t·ª´ PDF (n·∫øu PDF c√≥ text layer)
    """
    doc = None
    try:
        # ƒê·∫£m b·∫£o file_buffer l√† bytes
        if isinstance(file_buffer, io.BytesIO):
            file_buffer.seek(0)
            file_buffer = file_buffer.read()
        elif not isinstance(file_buffer, bytes):
            file_buffer = bytes(file_buffer)
        
        doc = fitz.open(stream=file_buffer, filetype="pdf")
        total_pages = len(doc)
        text_parts = []
        
        for page_num in range(total_pages):
            try:
                page = doc[page_num]
                text = page.get_text()
                if text.strip():
                    text_parts.append(f"--- Trang {page_num + 1} ---\n{text}")
            except Exception as page_err:
                print(f"  ‚ö†Ô∏è  L·ªói khi ƒë·ªçc trang {page_num + 1}: {str(page_err)}")
                continue
        
        full_text = "\n\n".join(text_parts)
        
        # Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng text
        text_length = len(full_text)
        word_count = len(full_text.split())
        has_vietnamese = any('\u0103' <= char <= '\u1ef9' or char in '√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë' 
                           for char in full_text)
        
        is_real_text = text_length > 100 and word_count > 10 and has_vietnamese
        
        return {
            'text': full_text,
            'pages': total_pages,
            'text_length': text_length,
            'word_count': word_count,
            'is_real_text': is_real_text,
            'confidence': 100 if is_real_text else 30
        }
    except Exception as e:
        raise Exception(f"L·ªói khi ƒë·ªçc PDF: {str(e)}")
    finally:
        # ƒê·∫£m b·∫£o document ƒë∆∞·ª£c ƒë√≥ng
        if doc is not None:
            try:
                doc.close()
            except:
                pass

def pdf_to_images(file_buffer):
    """
    Convert PDF pages to images ƒë·ªÉ OCR
    X·ª≠ l√Ω t·ª´ng trang v·ªõi error handling - n·∫øu m·ªôt trang l·ªói, skip v√† ti·∫øp t·ª•c
    """
    try:
        # ƒê·∫£m b·∫£o file_buffer l√† bytes
        if isinstance(file_buffer, io.BytesIO):
            file_buffer.seek(0)
            file_buffer = file_buffer.read()
        elif not isinstance(file_buffer, bytes):
            file_buffer = bytes(file_buffer)
        
        doc = fitz.open(stream=file_buffer, filetype="pdf")
        total_pages = len(doc)
        images = []
        failed_pages = []
        
        print(f"üìÑ PDF c√≥ {total_pages} trang, ƒëang chuy·ªÉn sang ·∫£nh...")
        
        try:
            for page_num in range(total_pages):
                pix = None
                try:
                    page = doc[page_num]
                    # Render v·ªõi scale cao ƒë·ªÉ OCR t·ªët h∆°n
                    mat = fitz.Matrix(2.5, 2.5)  # 2.5x scale
                    pix = page.get_pixmap(matrix=mat)
                    
                    # Convert to PIL Image
                    img_data = pix.tobytes("png")
                    # Copy image ƒë·ªÉ tr√°nh reference issues v√† ƒë·∫£m b·∫£o ƒë·ªôc l·∫≠p
                    img = Image.open(io.BytesIO(img_data)).copy()
                    images.append(img)
                    print(f"  ‚úÖ Trang {page_num + 1}/{total_pages} ƒë√£ chuy·ªÉn sang ·∫£nh")
                except Exception as page_err:
                    print(f"  ‚ö†Ô∏è  L·ªói khi chuy·ªÉn trang {page_num + 1} sang ·∫£nh: {str(page_err)}")
                    failed_pages.append(page_num + 1)
                    continue
                finally:
                    # Gi·∫£i ph√≥ng pixmap ƒë·ªÉ tr√°nh memory leak
                    if pix is not None:
                        pix = None
        finally:
            # ƒê·∫£m b·∫£o document ƒë∆∞·ª£c ƒë√≥ng
            if doc is not None:
                try:
                    doc.close()
                except:
                    pass
        
        if failed_pages:
            print(f"‚ö†Ô∏è  {len(failed_pages)} trang kh√¥ng th·ªÉ chuy·ªÉn sang ·∫£nh: {failed_pages}")
        
        if not images:
            raise Exception("Kh√¥ng th·ªÉ chuy·ªÉn b·∫•t k·ª≥ trang n√†o sang ·∫£nh")
        
        print(f"‚úÖ ƒê√£ chuy·ªÉn {len(images)}/{total_pages} trang sang ·∫£nh th√†nh c√¥ng")
        return images
    except Exception as e:
        raise Exception(f"L·ªói khi chuy·ªÉn PDF sang ·∫£nh: {str(e)}")

def detect_text_alignment(line_items, image_width):
    """
    X√°c ƒë·ªãnh alignment c·ªßa text d·ª±a tr√™n v·ªã tr√≠ bounding box
    Logic ƒë∆°n gi·∫£n v√† ch√≠nh x√°c h∆°n:
    - So s√°nh margin tr√°i v√† ph·∫£i
    - N·∫øu margin tr√°i << margin ph·∫£i -> left
    - N·∫øu margin ph·∫£i << margin tr√°i -> right  
    - N·∫øu 2 margins t∆∞∆°ng ƒë·ªëi b·∫±ng nhau -> center
    
    Returns: 'left', 'center', 'right'
    """
    if not line_items or not image_width or image_width <= 0:
        return 'left'
    
    # T√≠nh v·ªã tr√≠ c·ªßa to√†n b·ªô line (leftmost v√† rightmost)
    leftmost = min([item['x'] for item in line_items])
    rightmost = max([max([pt[0] for pt in item['box']]) for item in line_items])
    
    # T√≠nh margins (kho·∫£ng c√°ch t·ª´ edge) - t√≠nh b·∫±ng pixel
    left_margin_px = leftmost
    right_margin_px = image_width - rightmost
    
    # T√≠nh ƒë·ªô r·ªông c·ªßa line
    line_width = rightmost - leftmost
    
    # T√≠nh t·ª∑ l·ªá margins
    left_margin_ratio = left_margin_px / image_width
    right_margin_ratio = right_margin_px / image_width
    
    # T√≠nh center c·ªßa line
    line_center = (leftmost + rightmost) / 2
    center_ratio = line_center / image_width
    
    # Debug info - B·∫¨T ƒë·ªÉ test v√† debug alignment
    if len(line_items) > 0:
        first_text = line_items[0].get('text', '')[:20]
        print(f"  [Alignment] '{first_text}...' | L:{left_margin_px:.0f}px({left_margin_ratio:.1%}) R:{right_margin_px:.0f}px({right_margin_ratio:.1%}) C:{center_ratio:.1%} W:{line_width:.0f}px")
    
    # T√≠nh ch√™nh l·ªách margins
    margin_diff_px = abs(left_margin_px - right_margin_px)
    margin_diff_ratio = abs(left_margin_ratio - right_margin_ratio)
    
    # Rule 1: N·∫øu line chi·∫øm > 90% width -> left (full width paragraph)
    if line_width / image_width > 0.90:
        result = 'left'
        print(f"    ‚Üí Rule 1: Full width -> {result}")
        return result
    
    # Rule 2: So s√°nh margins tr·ª±c ti·∫øp - ƒê∆†N GI·∫¢N NH·∫§T
    # N·∫øu ch√™nh l·ªách margin < 3% image width HO·∫∂C < 30px -> center
    threshold_px = max(30, image_width * 0.03)  # √çt nh·∫•t 30px ho·∫∑c 3% width
    if margin_diff_px < threshold_px:
        # Nh∆∞ng ph·∫£i c√≥ margin ·ªü c·∫£ 2 b√™n (kh√¥ng qu√° g·∫ßn edge)
        if left_margin_ratio > 0.02 and right_margin_ratio > 0.02:
            result = 'center'
            print(f"    ‚Üí Rule 2: Margins balanced -> {result}")
            return result
    
    # Rule 3: So s√°nh margins - left margin nh·ªè h∆°n -> left
    if left_margin_px < right_margin_px:
        # Ch√™nh l·ªách ph·∫£i ƒë√°ng k·ªÉ (> 5% width ho·∫∑c > 50px)
        if (right_margin_px - left_margin_px) > max(50, image_width * 0.05):
            result = 'left'
            print(f"    ‚Üí Rule 3: Left margin smaller -> {result}")
            return result
    
    # Rule 4: So s√°nh margins - right margin nh·ªè h∆°n -> right
    if right_margin_px < left_margin_px:
        # Ch√™nh l·ªách ph·∫£i ƒë√°ng k·ªÉ (> 5% width ho·∫∑c > 50px)
        if (left_margin_px - right_margin_px) > max(50, image_width * 0.05):
            result = 'right'
            print(f"    ‚Üí Rule 4: Right margin smaller -> {result}")
            return result
    
    # Rule 5: D·ª±a tr√™n v·ªã tr√≠ tuy·ªát ƒë·ªëi (edge detection)
    if left_margin_ratio < 0.02:  # R·∫•t g·∫ßn edge tr√°i
        result = 'left'
        print(f"    ‚Üí Rule 5a: Near left edge -> {result}")
        return result
    
    if right_margin_ratio < 0.02:  # R·∫•t g·∫ßn edge ph·∫£i
        result = 'right'
        print(f"    ‚Üí Rule 5b: Near right edge -> {result}")
        return result
    
    # Rule 6: Fallback - d·ª±a tr√™n center position
    if center_ratio < 0.47:
        result = 'left'
    elif center_ratio > 0.53:
        result = 'right'
    else:
        result = 'center'
    
    print(f"    ‚Üí Rule 6: Fallback (center={center_ratio:.1%}) -> {result}")
    return result

def format_line_with_spacing(line_items, image_width=None):
    """
    Format m·ªôt d√≤ng v·ªõi spacing v√† x√°c ƒë·ªãnh alignment
    S·ª≠ d·ª•ng bounding boxes ƒë·ªÉ t√≠nh to√°n ch√≠nh x√°c v·ªã tr√≠ v√† spacing
    """
    if not line_items:
        return {"text": "", "alignment": "left"}
    
    # Sort by X position (left to right)
    line_items.sort(key=lambda x: x['x'])
    
    # X√°c ƒë·ªãnh alignment
    alignment = 'left'
    if image_width and image_width > 0:
        alignment = detect_text_alignment(line_items, image_width)
    
    # Format text v·ªõi spacing
    if len(line_items) > 1:
        # Calculate spacing between items d·ª±a tr√™n bounding boxes
        spacings = []
        for i in range(len(line_items) - 1):
            # Calculate end of current item (rightmost x)
            current_end = max([pt[0] for pt in line_items[i]['box']])
            # Calculate start of next item (leftmost x)
            next_start = line_items[i + 1]['x']
            spacing = next_start - current_end
            spacings.append(spacing)
        
        # Format with multiple spaces ƒë·ªÉ preserve alignment - GI·ªÆ FORMAT PDF
        result_parts = []
        for i, item in enumerate(line_items):
            text = item.get('text', '')
            if not text:  # Skip n·∫øu kh√¥ng c√≥ text
                continue
                
            if i > 0:
                # Add spaces based on spacing - ch√≠nh x√°c h∆°n
                # ~6-8px per space character (t√πy font)
                pixel_spacing = spacings[i-1]
                spaces_needed = max(1, int(pixel_spacing / 7))  # 7px per space
                # Gi·ªõi h·∫°n t·ªëi ƒëa 20 spaces ƒë·ªÉ tr√°nh qu√° d√†i
                result_parts.append(' ' * min(spaces_needed, 20))
            # Strip ch·ªâ ·ªü ƒë·∫ßu/cu·ªëi, gi·ªØ nguy√™n spaces trong text
            result_parts.append(text.strip() if text.strip() else text)
        
        text_result = ''.join(result_parts) if result_parts else ''
    else:
        # Single item - join v·ªõi space, GI·ªÆ NGUY√äN t·∫•t c·∫£ text
        texts = []
        for item in line_items:
            text = item.get('text', '')
            if text:  # Ch·ªâ th√™m n·∫øu c√≥ text
                # Strip ch·ªâ ·ªü ƒë·∫ßu/cu·ªëi, gi·ªØ nguy√™n spaces trong text
                texts.append(text.strip() if text.strip() else text)
        
        text_result = ' '.join(texts) if texts else ''
    
    return {"text": text_result, "alignment": alignment}

def ocr_image(image, use_preprocessing=False):
    """
    OCR m·ªôt ·∫£nh v·ªõi PaddleOCR - Gi·ªØ layout (tables, columns, spacing)
    ƒê·∫¢M B·∫¢O KH√îNG M·∫§T CH·ªÆ - Default: T·∫ÆT preprocessing ƒë·ªÉ kh√¥ng l√†m m·∫•t text
    """
    try:
        # Preprocess NH·∫∏ n·∫øu c·∫ßn - Default T·∫ÆT ƒë·ªÉ kh√¥ng l√†m m·∫•t ch·ªØ
        if use_preprocessing:
            print("‚ö†Ô∏è  Preprocessing enabled - c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng text")
            image = preprocess_image_for_ocr(image)
        
        # Convert PIL to numpy array for PaddleOCR
        # ƒê·∫£m b·∫£o image l√† RGB mode tr∆∞·ªõc
        if image.mode != 'RGB':
            if image.mode == 'RGBA':
                # T·∫°o background tr·∫Øng cho RGBA
                rgb_image = Image.new('RGB', image.size, (255, 255, 255))
                rgb_image.paste(image, mask=image.split()[3] if image.mode == 'RGBA' else None)
                image = rgb_image
            else:
                image = image.convert('RGB')
        
        img_array = np.array(image)
        
        # ƒê·∫£m b·∫£o img_array c√≥ format ƒë√∫ng
        if len(img_array.shape) == 2:
            # Grayscale -> convert to BGR
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
        elif len(img_array.shape) == 3:
            # Color image - PIL l√† RGB, PaddleOCR c·∫ßn BGR
            if img_array.shape[2] == 4:  # RGBA (should not happen after conversion above)
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)
            elif img_array.shape[2] == 3:  # RGB
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else:
                raise Exception(f"Unsupported image format: {img_array.shape}")
        else:
            raise Exception(f"Invalid image array shape: {img_array.shape}")
        
        # ƒê·∫£m b·∫£o img_array l√† uint8
        if img_array.dtype != np.uint8:
            img_array = img_array.astype(np.uint8)
        
        # Perform OCR - ƒê·∫¢M B·∫¢O KH√îNG M·∫§T CH·ªÆ
        result = ocr_engine.ocr(img_array, cls=True)
        
        # Debug: Log k·∫øt qu·∫£ OCR
        if result:
            total_detected = len(result[0]) if result[0] else 0
            print(f"üìä PaddleOCR detected {total_detected} text items")
        
        # Extract text v·ªõi layout preservation - ƒê·∫¢M B·∫¢O KH√îNG M·∫§T CH·ªÆ
        texts = []
        confidences = []
        lines_with_alignment = []  # Store alignment info
        
        if result and result[0]:
            # Extract T·∫§T C·∫¢ text t·ª´ PaddleOCR - KH√îNG B·ªé S√ìT
            lines_sorted = []
            total_items = 0
            skipped_items = 0
            
            for line in result[0]:
                if line and len(line) >= 2:
                    try:
                        box = line[0]  # Bounding box
                        text_info = line[1]  # [text, confidence]
                        
                        # ƒê·∫£m b·∫£o text_info l√† list/tuple v√† c√≥ √≠t nh·∫•t text
                        if isinstance(text_info, (list, tuple)) and len(text_info) > 0:
                            text = str(text_info[0]) if text_info[0] else ""
                            confidence = float(text_info[1]) if len(text_info) > 1 else 0.0
                        else:
                            # Fallback: text_info c√≥ th·ªÉ l√† string
                            text = str(text_info) if text_info else ""
                            confidence = 0.0
                        
                        # KH√îNG FILTER - L·∫•y T·∫§T C·∫¢ text, k·ªÉ c·∫£ confidence th·∫•p ho·∫∑c text c√≥ v·∫•n ƒë·ªÅ
                        # Ch·ªâ skip n·∫øu text l√† None ho·∫∑c ho√†n to√†n r·ªóng (kh√¥ng c√≥ k√Ω t·ª± n√†o)
                        if text is None:
                            skipped_items += 1
                            continue
                        
                        # Gi·ªØ c·∫£ text ch·ªâ c√≥ spaces (c√≥ th·ªÉ l√† d√≤ng tr·ªëng ho·∫∑c spacing)
                        # Ch·ªâ skip n·∫øu th·ª±c s·ª± kh√¥ng c√≥ k√Ω t·ª± n√†o
                        text_str = str(text).strip()
                        if not text_str:
                            skipped_items += 1
                            continue
                        
                        y_pos = min([pt[1] for pt in box])
                        x_pos = min([pt[0] for pt in box])
                        lines_sorted.append({
                            'y': y_pos,
                            'x': x_pos,
                            'text': text,  # Gi·ªØ nguy√™n text, kh√¥ng strip ·ªü ƒë√¢y
                            'confidence': confidence,
                            'box': box
                        })
                        total_items += 1
                    except Exception as e:
                        print(f"‚ö†Ô∏è  L·ªói khi extract text t·ª´ line: {str(e)}, line: {line}")
                        skipped_items += 1
                        continue
            
            print(f"üìä OCR Extraction Stats:")
            print(f"   ‚úÖ Extracted: {total_items} items")
            print(f"   ‚ö†Ô∏è  Skipped: {skipped_items} items (empty text)")
            print(f"   üìà Success rate: {(total_items / len(result[0]) * 100) if result[0] else 0:.1f}%")
            
            # Sort by Y position (top to bottom), then X (left to right)
            lines_sorted.sort(key=lambda x: (round(x['y'] / 10) * 10, x['x']))
            
            # Get image width t·ª´ image size - QUAN TR·ªåNG cho alignment detection
            img_width = img_array.shape[1] if len(img_array.shape) > 1 else None
            if img_width is None or img_width <= 0:
                # Fallback: t√≠nh t·ª´ bounding boxes n·∫øu c√≥
                if result and result[0] and len(result[0]) > 0:
                    all_x_coords = []
                    for line in result[0]:
                        if line and len(line) >= 2:
                            box = line[0]
                            all_x_coords.extend([pt[0] for pt in box])
                    if all_x_coords:
                        img_width = max(all_x_coords) + 50  # Th√™m margin
                else:
                    img_width = 1000  # Default fallback
            
            # Group into lines and preserve layout v·ªõi alignment
            current_line_items = []
            current_line_y = None
            lines_with_alignment = []  # Store lines with alignment info
            
            for item in lines_sorted:
                # Group items on same line (Y position similar)
                # TƒÉng threshold ƒë·ªÉ group t·ªët h∆°n v√† kh√¥ng m·∫•t text
                if current_line_y is None or abs(item['y'] - current_line_y) < 20:
                    current_line_items.append(item)
                    if current_line_y is None:
                        current_line_y = item['y']
                else:
                    # New line - format previous line v·ªõi layout v√† alignment
                    if current_line_items:
                        formatted_result = format_line_with_spacing(current_line_items, img_width)
                        formatted_line = formatted_result.get('text', '')
                        alignment = formatted_result.get('alignment', 'left')
                        
                        # ƒê·∫£m b·∫£o kh√¥ng m·∫•t text - n·∫øu formatted_line r·ªóng nh∆∞ng c√≥ text, d√πng text g·ªëc
                        if not formatted_line or not formatted_line.strip():
                            # Fallback: join t·∫•t c·∫£ text t·ª´ items
                            fallback_text = ' '.join([item['text'] for item in current_line_items if item.get('text')])
                            if fallback_text:
                                formatted_line = fallback_text
                        
                        if formatted_line:  # Ch·ªâ append n·∫øu c√≥ text
                            texts.append(formatted_line)
                            confidences.append(sum([i['confidence'] for i in current_line_items]) / len(current_line_items))
                            lines_with_alignment.append({
                                'text': formatted_line,
                                'alignment': alignment
                            })
                    
                    current_line_items = [item]
                    current_line_y = item['y']
            
            # Process last line
            if current_line_items:
                formatted_result = format_line_with_spacing(current_line_items, img_width)
                formatted_line = formatted_result.get('text', '')
                alignment = formatted_result.get('alignment', 'left')
                
                # ƒê·∫£m b·∫£o kh√¥ng m·∫•t text
                if not formatted_line or not formatted_line.strip():
                    fallback_text = ' '.join([item['text'] for item in current_line_items if item.get('text')])
                    if fallback_text:
                        formatted_line = fallback_text
                
                if formatted_line:  # Ch·ªâ append n·∫øu c√≥ text
                    texts.append(formatted_line)
                    confidences.append(sum([i['confidence'] for i in current_line_items]) / len(current_line_items))
                    lines_with_alignment.append({
                        'text': formatted_line,
                        'alignment': alignment
                    })
        
        full_text = "\n".join(texts)
        avg_confidence = sum(confidences) / len(confidences) * 100 if confidences else 0
        
        return {
            'text': full_text,
            'confidence': avg_confidence,
            'words': len(texts),
            'lines_with_alignment': lines_with_alignment  # Th√™m alignment info
        }
    except Exception as e:
        raise Exception(f"L·ªói khi OCR ·∫£nh: {str(e)}")

def process_pdf(file_buffer, force_ocr=False, use_text_correction=True):
    """
    X·ª≠ l√Ω PDF file - th·ª≠ extract text tr∆∞·ªõc, n·∫øu kh√¥ng ƒë∆∞·ª£c th√¨ OCR
    """
    start_time = time.time()
    
    # ƒê·∫£m b·∫£o file_buffer l√† bytes (handle tr∆∞·ªùng h·ª£p Chrome PDF viewer)
    if isinstance(file_buffer, io.BytesIO):
        file_buffer.seek(0)
        file_buffer = file_buffer.read()
    elif not isinstance(file_buffer, bytes):
        file_buffer = bytes(file_buffer)
    
    # Th·ª≠ extract text tr∆∞·ªõc
    if not force_ocr:
        try:
            extracted = extract_text_from_pdf(file_buffer)
            if extracted['is_real_text'] and extracted['confidence'] >= 80:
                text = extracted['text']
                
                # Apply text correction qua API - s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát
                corrected_text = text
                if use_text_correction and TEXT_CORRECTION_AVAILABLE:
                    print("ƒêang g·ªçi Text Correction API ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát...")
                    corrected_text = correct_vietnamese_text(text, use_correction=True)
                
                processing_time = time.time() - start_time
                
                # PH√ÇN T√ÅCH: text (text thu·∫ßn) v√† html (HTML)
                # N·∫øu corrected_text c√≥ HTML tags -> extract text thu·∫ßn v√† gi·ªØ HTML
                # N·∫øu corrected_text l√† text thu·∫ßn -> gi·ªØ text v√† convert sang HTML
                has_html_tags = '<' in corrected_text and '>' in corrected_text and re.search(r'<[^>]+>', corrected_text)
                
                if has_html_tags:
                    # Text ƒëang ch·ª©a HTML -> extract text thu·∫ßn
                    plain_text = extract_text_from_html(corrected_text)
                    html_content = corrected_text
                else:
                    # Text thu·∫ßn -> convert sang HTML
                    plain_text = corrected_text
                    html_content = text_to_html_paragraphs(corrected_text)
                
                result_data = {
                    'success': True,
                    'text': plain_text,  # Text thu·∫ßn (kh√¥ng c√≥ HTML tags)
                    'html': html_content,  # HTML (c√≥ HTML tags)
                    'pages': extracted['pages'],
                    'confidence': extracted['confidence'],
                    'method': 'direct_extraction',
                    'text_correction': use_text_correction and TEXT_CORRECTION_AVAILABLE,
                    'processing_time': f"{processing_time:.2f}s",
                    'text_length': len(plain_text),
                    'word_count': len(plain_text.split())
                }
                
                return result_data
        except Exception as e:
            print(f"Text extraction failed: {e}")
    
    # N·∫øu kh√¥ng ƒë∆∞·ª£c, OCR
    print("PDF kh√¥ng c√≥ text layer t·ªët, ƒëang OCR...")
    
    try:
        # Convert PDF to images
        images = pdf_to_images(file_buffer)
        print(f"ƒê√£ chuy·ªÉn ƒë·ªïi {len(images)} trang sang ·∫£nh")
        
        # OCR t·ª´ng trang v√† g·ªçi ProtonX s·ª≠a ch√≠nh t·∫£ ngay sau m·ªói trang
        # X·ª≠ l√Ω t·ª´ng trang v·ªõi error handling ri√™ng - n·∫øu m·ªôt trang l·ªói, skip v√† ti·∫øp t·ª•c
        all_texts = []
        all_confidences = []
        failed_pages = []
        
        for idx, img in enumerate(images):
            try:
                print(f"\n[{idx + 1}/{len(images)}] ƒêang OCR trang {idx + 1}...")
                
                # OCR trang n√†y - ƒë·∫£m b·∫£o image ƒë∆∞·ª£c copy ƒë·ªÉ tr√°nh reference issues
                try:
                    # Copy image ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªôc l·∫≠p
                    img_copy = img.copy() if hasattr(img, 'copy') else img
                    result = ocr_image(img_copy, use_preprocessing=False)  # T·∫ÆT preprocessing ƒë·ªÉ kh√¥ng m·∫•t ch·ªØ
                except Exception as ocr_err:
                    print(f"  ‚ö†Ô∏è  L·ªói khi OCR trang {idx + 1}: {str(ocr_err)}")
                    failed_pages.append(idx + 1)
                    all_texts.append(f"--- Trang {idx + 1} ---\n[L·ªói khi OCR trang n√†y: {str(ocr_err)}]")
                    all_confidences.append(0.0)
                    continue
                
                if result and result.get('text'):
                    page_text = result['text']
                    
                    # G·ªçi API ngay sau khi OCR xong t·ª´ng trang ƒë·ªÉ s·ª≠a ch√≠nh t·∫£
                    if use_text_correction and TEXT_CORRECTION_AVAILABLE:
                        try:
                            print(f"  ‚Üí G·ªçi Text Correction API ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát trang {idx + 1}...")
                            corrected_page_text = correct_vietnamese_text(page_text, use_correction=True)
                            print(f"  ‚úÖ ƒê√£ s·ª≠a ch√≠nh t·∫£ trang {idx + 1} xong")
                            all_texts.append(f"--- Trang {idx + 1} ---\n{corrected_page_text}")
                        except Exception as correction_err:
                            print(f"  ‚ö†Ô∏è  L·ªói khi s·ª≠a ch√≠nh t·∫£ trang {idx + 1}: {str(correction_err)}, gi·ªØ nguy√™n text g·ªëc")
                            all_texts.append(f"--- Trang {idx + 1} ---\n{page_text}")
                    else:
                        all_texts.append(f"--- Trang {idx + 1} ---\n{page_text}")
                    
                    all_confidences.append(result.get('confidence', 0.0))
                else:
                    print(f"  ‚ö†Ô∏è  Trang {idx + 1} kh√¥ng c√≥ text ƒë∆∞·ª£c detect")
                    all_texts.append(f"--- Trang {idx + 1} ---\n[Kh√¥ng c√≥ text ƒë∆∞·ª£c ph√°t hi·ªán]")
                    all_confidences.append(0.0)
                    
            except Exception as page_err:
                print(f"  ‚ùå L·ªói khi x·ª≠ l√Ω trang {idx + 1}: {str(page_err)}")
                failed_pages.append(idx + 1)
                all_texts.append(f"--- Trang {idx + 1} ---\n[L·ªói: {str(page_err)}]")
                all_confidences.append(0.0)
                continue
        
        # Log k·∫øt qu·∫£
        success_pages = len(images) - len(failed_pages)
        print(f"\nüìä K·∫øt qu·∫£ x·ª≠ l√Ω PDF:")
        print(f"   ‚úÖ Th√†nh c√¥ng: {success_pages}/{len(images)} trang")
        if failed_pages:
            print(f"   ‚ö†Ô∏è  L·ªói: {len(failed_pages)} trang ({', '.join(map(str, failed_pages))})")
        
        # K·∫øt h·ª£p t·∫•t c·∫£ c√°c trang ƒë√£ ƒë∆∞·ª£c s·ª≠a ch√≠nh t·∫£
        combined_text = "\n\n".join(all_texts)
        
        # PH√ÇN T√ÅCH: text (text thu·∫ßn) v√† html (HTML)
        # N·∫øu combined_text c√≥ HTML tags -> extract text thu·∫ßn v√† gi·ªØ HTML
        # N·∫øu combined_text l√† text thu·∫ßn -> gi·ªØ text v√† convert sang HTML
        has_html_tags = '<' in combined_text and '>' in combined_text and re.search(r'<[^>]+>', combined_text)
        
        if has_html_tags:
            # Text ƒëang ch·ª©a HTML -> extract text thu·∫ßn
            plain_text = extract_text_from_html(combined_text)
            html_content = combined_text
        else:
            # Text thu·∫ßn -> convert sang HTML (kh√¥ng c√≥ alignment info t·ª´ PDF extraction)
            plain_text = combined_text
            html_content = text_to_html_paragraphs(combined_text)
        
        avg_confidence = sum(all_confidences) / len(all_confidences) if all_confidences else 0
        processing_time = time.time() - start_time
        
        # T√≠nh s·ªë trang th√†nh c√¥ng
        success_pages = len(images) - len(failed_pages) if failed_pages else len(images)
        
        result = {
            'success': True,
            'text': plain_text,  # Text thu·∫ßn (kh√¥ng c√≥ HTML tags)
            'html': html_content,  # HTML (c√≥ HTML tags)
            'pages': len(images),
            'success_pages': success_pages,
            'failed_pages': failed_pages if failed_pages else [],
            'confidence': avg_confidence,
            'method': 'ocr',
            'text_correction': use_text_correction and TEXT_CORRECTION_AVAILABLE,
            'processing_time': f"{processing_time:.2f}s",
            'text_length': len(plain_text),
            'word_count': len(plain_text.split())
        }
        
        # N·∫øu c√≥ trang l·ªói, v·∫´n tr·∫£ v·ªÅ success nh∆∞ng c√≥ warning
        if failed_pages:
            result['warning'] = f"M·ªôt s·ªë trang ({len(failed_pages)} trang) kh√¥ng th·ªÉ x·ª≠ l√Ω ƒë∆∞·ª£c"
        
        return result
    except Exception as e:
        processing_time = time.time() - start_time
        return {
            'success': False,
            'text': '',
            'error': f"L·ªói khi OCR PDF: {str(e)}",
            'processing_time': f"{processing_time:.2f}s",
            'method': 'ocr_failed'
        }

def process_image(file_buffer, use_text_correction=True):
    """
    X·ª≠ l√Ω image file
    """
    start_time = time.time()
    
    try:
        # Open image - PIL s·∫Ω t·ª± ƒë·ªông handle nhi·ªÅu format (PNG, JPG, GIF, BMP, WEBP, TIFF, etc.)
        try:
            image = Image.open(io.BytesIO(file_buffer))
            # Verify image is valid
            image.verify()
            # Reopen because verify() closes the image
            image = Image.open(io.BytesIO(file_buffer))
        except Exception as img_error:
            raise Exception(f"Kh√¥ng th·ªÉ m·ªü file ·∫£nh: {str(img_error)}. Vui l√≤ng ƒë·∫£m b·∫£o file l√† ·∫£nh h·ª£p l·ªá (PNG, JPG, JPEG, GIF, BMP, WEBP, TIFF, etc.)")
        
        # OCR
        result = ocr_image(image, use_preprocessing=False)  # T·∫ÆT preprocessing ƒë·ªÉ kh√¥ng m·∫•t ch·ªØ
        
        # Apply text correction qua API - s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát
        text = result['text']
        lines_with_alignment = result.get('lines_with_alignment', [])
        
        if use_text_correction and TEXT_CORRECTION_AVAILABLE:
            print("ƒêang g·ªçi Text Correction API ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát...")
            text = correct_vietnamese_text(text, use_correction=True)
            # C·∫≠p nh·∫≠t text trong lines_with_alignment sau khi correction
            # (gi·ªØ nguy√™n alignment, ch·ªâ update text)
            corrected_lines = text.split('\n')
            for i, line_info in enumerate(lines_with_alignment):
                if i < len(corrected_lines):
                    line_info['text'] = corrected_lines[i]
        
        processing_time = time.time() - start_time
        
        # PH√ÇN T√ÅCH: text (text thu·∫ßn) v√† html (HTML)
        # N·∫øu text c√≥ HTML tags -> extract text thu·∫ßn v√† gi·ªØ HTML
        # N·∫øu text l√† text thu·∫ßn -> gi·ªØ text v√† convert sang HTML v·ªõi alignment
        has_html_tags = '<' in text and '>' in text and re.search(r'<[^>]+>', text)
        
        if has_html_tags:
            # Text ƒëang ch·ª©a HTML -> extract text thu·∫ßn
            plain_text = extract_text_from_html(text)
            html_content = text
        else:
            # Text thu·∫ßn -> convert sang HTML v·ªõi alignment
            plain_text = text
            html_content = text_to_html_paragraphs_with_alignment(text, lines_with_alignment)
        
        result_data = {
            'success': True,
            'text': plain_text,  # Text thu·∫ßn (kh√¥ng c√≥ HTML tags)
            'html': html_content,  # HTML (c√≥ HTML tags)
            'confidence': result['confidence'],
            'method': 'ocr',
            'text_correction': use_text_correction and TEXT_CORRECTION_AVAILABLE,
            'processing_time': f"{processing_time:.2f}s",
            'text_length': len(plain_text),
            'word_count': len(plain_text.split())
        }
        
        return result_data
    except Exception as e:
        processing_time = time.time() - start_time
        return {
            'success': False,
            'text': '',
            'error': f"L·ªói khi OCR ·∫£nh: {str(e)}",
            'processing_time': f"{processing_time:.2f}s",
            'method': 'ocr_failed'
        }

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'success': True,
        'status': 'healthy',
        'message': 'OCR service ƒëang ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng',
        'engine': 'PaddleOCR',
        'language': 'Vietnamese (vi)',
        'text_correction': {
            'available': TEXT_CORRECTION_AVAILABLE,
            'method': 'api',
            'api_url': TEXT_CORRECTION_API_URL if TEXT_CORRECTION_AVAILABLE else None,
            'description': 'Sau khi PaddleOCR l·∫•y text ‚Üí G·ªçi API ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ ti·∫øng Vi·ªát chu·∫©n' if TEXT_CORRECTION_AVAILABLE else None
        },
        'supported_formats': list(ALLOWED_EXTENSIONS)
    })

@app.route('/extract-text', methods=['POST'])
def extract_text():
    """
    Extract text from PDF or Image
    POST /extract-text
    FormData: file (PDF or Image), forceOCR (optional), language (optional)
    """
    try:
        # Check if file is present
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c upload'
            }), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'
            }), 400
        
        # Check file size
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > MAX_FILE_SIZE:
            return jsonify({
                'success': False,
                'message': f'File qu√° l·ªõn. K√≠ch th∆∞·ªõc t·ªëi ƒëa: {MAX_FILE_SIZE / 1024 / 1024}MB'
            }), 400
        
        # Read file to buffer first (need to check content type)
        # Reset file pointer tr∆∞·ªõc khi ƒë·ªçc
        file.seek(0)
        file_buffer = file.read()
        # T·∫°o BytesIO m·ªõi ƒë·ªÉ ƒë·∫£m b·∫£o clean state
        file_buffer_io = io.BytesIO(file_buffer)
        file_buffer_io.seek(0)
        
        # Check file type by content, not just extension (more flexible)
        # Also check content-type header (Chrome PDF viewer might send application/pdf)
        content_type = request.content_type or request.headers.get('Content-Type', '') or ''
        filename_lower = (file.filename or '').lower()
        
        # Check if it's PDF first (by content-type, filename, or content)
        is_pdf = False
        # Check content-type header (Chrome PDF viewer sends application/pdf)
        if 'application/pdf' in content_type:
            is_pdf = True
            print(f"‚úÖ Detected PDF by Content-Type: {content_type}")
        elif filename_lower.endswith('.pdf'):
            # Check by content to verify
            is_pdf = is_pdf_file(file.filename, file_buffer_io)
            if is_pdf:
                print(f"‚úÖ Detected PDF by filename and content: {file.filename}")
        else:
            # Check by content only
            is_pdf = is_pdf_file(file.filename, file_buffer_io)
            if is_pdf:
                print(f"‚úÖ Detected PDF by content (no extension): {file.filename}")
        
        # If not PDF, check if it's image
        is_image = False
        if not is_pdf:
            # Check content-type for images
            if any(ct in content_type for ct in ['image/', 'image/png', 'image/jpeg', 'image/jpg', 'image/gif', 'image/bmp', 'image/webp', 'image/tiff']):
                is_image = is_image_file(file.filename, file_buffer_io)
            else:
                is_image = is_image_file(file.filename, file_buffer_io)
        
        if not is_pdf and not is_image:
            # Try extension check as fallback
            if not allowed_file(file.filename):
                return jsonify({
                    'success': False,
                    'message': f'File type kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. H·ªó tr·ª£: PDF v√† c√°c ƒë·ªãnh d·∫°ng ·∫£nh (PNG, JPG, JPEG, GIF, BMP, WEBP, TIFF, etc.)'
                }), 400
        
        # Get options
        force_ocr = request.form.get('forceOCR', 'false').lower() == 'true'
        use_text_correction = request.form.get('useTextCorrection', 'true').lower() == 'true'  # Default: enabled
        
        # Process based on detected file type (use content detection)
        if is_pdf:
            result = process_pdf(file_buffer, force_ocr=force_ocr, use_text_correction=use_text_correction)
        elif is_image:
            result = process_image(file_buffer, use_text_correction=use_text_correction)
        else:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i file. Vui l√≤ng upload file PDF ho·∫∑c ·∫£nh h·ª£p l·ªá.'
            }), 400
        
        # Return result
        if result.get('success'):
            # Debug: Check if HTML is in result
            if 'html' in result:
                print(f"‚úÖ Returning result with HTML (length: {len(result['html'])})")
            else:
                print("‚ö†Ô∏è  Returning result WITHOUT HTML")
            return jsonify(result)
        else:
            return jsonify(result), 200  # Return 200 but with error in body
        
    except Exception as e:
        print(f"Error in extract_text: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'ƒê√£ x·∫£y ra l·ªói: {str(e)}',
            'error': str(e)
        }), 500
    finally:
        # Cleanup - ƒë·∫£m b·∫£o kh√¥ng c√≥ resource leak sau m·ªói request
        import gc
        gc.collect()

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 4000))  # Port 4000 cho OCR service, 5001 cho Text Correction API
    print(f"üöÄ OCR Service ƒëang ch·∫°y tr√™n port {port}")
    print(f"üìù Chuy√™n x·ª≠ l√Ω OCR ti·∫øng Vi·ªát v·ªõi PaddleOCR")
    print(f"üí° Text Correction API: {TEXT_CORRECTION_API_URL}")
    app.run(host='0.0.0.0', port=port, debug=False)

