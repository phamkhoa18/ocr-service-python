"""
Vietnamese Text Correction Module
Sá»­ dá»¥ng ProtonX Legal Text Correction model Ä‘á»ƒ chá»‰nh sá»­a vÄƒn báº£n sau OCR
Model: protonx-models/protonx-legal-tc
"""

import re

# Optional imports - khÃ´ng fail náº¿u khÃ´ng cÃ³ torch/transformers
TORCH_AVAILABLE = False
torch = None
AutoTokenizer = None
AutoModelForSeq2SeqLM = None

try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
    TORCH_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  Warning: torch/transformers khÃ´ng kháº£ dá»¥ng. Text correction sáº½ bá»‹ táº¯t.")
    print(f"   Error: {str(e)}")
    TORCH_AVAILABLE = False
except OSError as e:
    print(f"âš ï¸  Warning: Lá»—i khi load torch DLL. Text correction sáº½ bá»‹ táº¯t.")
    print(f"   Error: {str(e)}")
    print(f"ğŸ’¡ Gá»£i Ã½: Thá»­ cÃ i láº¡i torch hoáº·c táº¯t text correction.")
    TORCH_AVAILABLE = False
except Exception as e:
    print(f"âš ï¸  Warning: Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi import torch. Text correction sáº½ bá»‹ táº¯t.")
    print(f"   Error: {str(e)}")
    TORCH_AVAILABLE = False

class VietnameseTextCorrector:
    """Vietnamese Text Corrector using ProtonX Legal TC model"""
    
    def __init__(self, model_path="protonx-models/protonx-legal-tc", use_gpu=False):
        """
        Initialize the text correction model
        
        Args:
            model_path: Hugging Face model path
            use_gpu: Use GPU if available
        """
        self.model_path = model_path
        self.use_gpu = use_gpu
        self.model = None
        self.tokenizer = None
        self.device = None
        self.initialized = False
        
    def _initialize_model(self):
        """Lazy initialization of the model"""
        if self.initialized:
            return
        
        # Check if torch is available
        if not TORCH_AVAILABLE:
            print("âŒ torch/transformers khÃ´ng kháº£ dá»¥ng. Text correction khÃ´ng thá»ƒ sá»­ dá»¥ng.")
            self.initialized = False
            return
            
        try:
            print("ğŸ”„ Äang táº£i ProtonX Text Correction model...")
            print(f"   Model: {self.model_path}")
            print("   âš ï¸  Láº§n Ä‘áº§u tiÃªn sáº½ download model (~500MB-1GB), cáº§n internet!")
            
            # Set device
            self.device = torch.device("cuda" if (self.use_gpu and torch.cuda.is_available()) else "cpu")
            print(f"   Device: {self.device}")
            
            # Load tokenizer
            print("   â†’ Äang táº£i tokenizer...")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            print("   âœ… Tokenizer Ä‘Ã£ táº£i xong")
            
            # Load model
            print("   â†’ Äang táº£i model (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)...")
            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_path)
            print("   âœ… Model Ä‘Ã£ táº£i xong")
            
            # Move to device
            print(f"   â†’ Äang chuyá»ƒn model sang {self.device}...")
            self.model.to(self.device)
            self.model.eval()
            print(f"   âœ… Model Ä‘Ã£ chuyá»ƒn sang {self.device}")
            
            self.initialized = True
            print("âœ… ProtonX Text Correction model Ä‘Ã£ sáºµn sÃ ng!")
            
        except Exception as e:
            import traceback
            print(f"âŒ Lá»—i khi khá»Ÿi táº¡o Text Correction model: {str(e)}")
            print("âš ï¸  Text correction sáº½ bá»‹ táº¯t. OCR sáº½ tráº£ vá» text gá»‘c.")
            print("\nğŸ“‹ Chi tiáº¿t lá»—i:")
            traceback.print_exc()
            self.initialized = False
    
    def correct_text(self, text, max_length=128):
        """
        Correct Vietnamese text
        
        Args:
            text: Input text to correct
            max_length: Maximum sequence length (default: 128 tokens)
            
        Returns:
            Corrected text
        """
        if not text or not text.strip():
            return text
        
        print(f"ğŸ“ Input text length: {len(text)} chars")
        print(f"ğŸ“ Input text preview: {text[:100]}...")
        
        # Initialize model if not already done
        if not self.initialized:
            print("ğŸ”„ Model chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o, Ä‘ang khá»Ÿi táº¡o...")
            try:
                self._initialize_model()
            except Exception as e:
                print(f"âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o model: {str(e)}")
                return text  # Return original text if model fails
        
        if not self.initialized:
            print("âš ï¸  Model khÃ´ng Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng, tráº£ vá» text gá»‘c")
            return text
        
        print(f"âœ… Model Ä‘Ã£ sáºµn sÃ ng, Ä‘ang sá»­a chÃ­nh táº£...")
        
        try:
            # Split text into sentences/chunks if too long
            # Model max length is 128 tokens
            sentences = self._split_into_sentences(text)
            print(f"ğŸ“ ÄÃ£ tÃ¡ch thÃ nh {len(sentences)} cÃ¢u")
            
            corrected_parts = []
            
            for idx, sentence in enumerate(sentences):
                if not sentence.strip():
                    corrected_parts.append(sentence)
                    continue
                
                print(f"   â†’ Äang sá»­a cÃ¢u {idx + 1}/{len(sentences)}: {sentence[:50]}...")
                
                # Truncate if too long (max 128 tokens)
                inputs = self.tokenizer(
                    sentence,
                    return_tensors="pt",
                    truncation=True,
                    max_length=max_length,
                    padding=True
                ).to(self.device)
                
                # Generate corrected text
                with torch.no_grad():
                    outputs = self.model.generate(
                        **inputs,
                        num_beams=10,
                        max_new_tokens=max_length,
                        length_penalty=1.0,
                        early_stopping=True,
                        repetition_penalty=1.2,
                        no_repeat_ngram_size=2,
                        pad_token_id=self.tokenizer.pad_token_id,
                        eos_token_id=self.tokenizer.eos_token_id,
                    )
                
                corrected = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                print(f"      âœ… ÄÃ£ sá»­a: {corrected[:50]}...")
                corrected_parts.append(corrected)
            
            # Join corrected parts
            corrected_text = "\n".join(corrected_parts)
            
            print(f"âœ… ÄÃ£ sá»­a xong, output length: {len(corrected_text)} chars")
            print(f"ğŸ“ Output preview: {corrected_text[:100]}...")
            
            return corrected_text
            
        except Exception as e:
            import traceback
            print(f"âš ï¸  Lá»—i khi correct text: {str(e)}")
            print("ğŸ“‹ Chi tiáº¿t lá»—i:")
            traceback.print_exc()
            return text  # Return original text on error
    
    def correct_long_text(self, text, chunk_size=128, overlap=20):
        """
        Correct long text by splitting into chunks vÃ  xá»­ lÃ½ tá»«ng pháº§n
        
        Args:
            text: Long text to correct
            chunk_size: Size of each chunk in tokens (default: 128)
            overlap: Overlap between chunks in tokens (default: 20)
            
        Returns:
            Corrected text
        """
        if not text or not text.strip():
            return text
        
        print(f"ğŸ“ Text dÃ i ({len(text)} chars), Ä‘ang chia nhá» Ä‘á»ƒ xá»­ lÃ½...")
        
        # Check if torch is available
        if not TORCH_AVAILABLE:
            return text  # Return original if torch not available
        
        # Initialize model if not already done
        if not self.initialized:
            print("â†’ Model chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o, Ä‘ang khá»Ÿi táº¡o...")
            self._initialize_model()
        
        if not self.initialized:
            print("âš ï¸  Model khÃ´ng Ä‘Æ°á»£c khá»Ÿi táº¡o, tráº£ vá» text gá»‘c")
            return text  # Return original if initialization failed
        
        try:
            # Split text by lines first (giá»¯ nguyÃªn cáº¥u trÃºc)
            lines = text.split('\n')
            print(f"ğŸ“ ÄÃ£ tÃ¡ch thÃ nh {len(lines)} dÃ²ng")
            
            # Process each line (hoáº·c group of lines)
            corrected_lines = []
            
            for line_idx, line in enumerate(lines):
                if not line.strip():
                    corrected_lines.append(line)  # Giá»¯ nguyÃªn dÃ²ng trá»‘ng
                    continue
                
                # Náº¿u dÃ²ng quÃ¡ dÃ i, chia nhá» hÆ¡n
                if len(line) > 200:  # Náº¿u dÃ²ng quÃ¡ 200 kÃ½ tá»±
                    print(f"   â†’ DÃ²ng {line_idx + 1} quÃ¡ dÃ i ({len(line)} chars), Ä‘ang chia nhá»...")
                    
                    # Chia dÃ²ng thÃ nh cÃ¡c cÃ¢u nhá» hÆ¡n
                    sentences = self._split_into_sentences(line)
                    corrected_line_parts = []
                    
                    for sentence in sentences:
                        if not sentence.strip():
                            continue
                        
                        # Sá»­a tá»«ng cÃ¢u
                        try:
                            corrected_sentence = self.correct_text(sentence, max_length=chunk_size)
                            corrected_line_parts.append(corrected_sentence)
                        except Exception as e:
                            print(f"      âš ï¸  Lá»—i khi sá»­a cÃ¢u: {str(e)}")
                            corrected_line_parts.append(sentence)  # Giá»¯ nguyÃªn náº¿u lá»—i
                    
                    corrected_line = " ".join(corrected_line_parts)
                    corrected_lines.append(corrected_line)
                else:
                    # DÃ²ng ngáº¯n, sá»­a trá»±c tiáº¿p
                    try:
                        corrected_line = self.correct_text(line, max_length=chunk_size)
                        corrected_lines.append(corrected_line)
                    except Exception as e:
                        print(f"   âš ï¸  Lá»—i khi sá»­a dÃ²ng {line_idx + 1}: {str(e)}")
                        corrected_lines.append(line)  # Giá»¯ nguyÃªn náº¿u lá»—i
            
            result = "\n".join(corrected_lines)
            print(f"âœ… ÄÃ£ xá»­ lÃ½ xong {len(corrected_lines)} dÃ²ng")
            
            return result
            
        except Exception as e:
            import traceback
            print(f"âš ï¸  Lá»—i khi correct long text: {str(e)}")
            print("ğŸ“‹ Chi tiáº¿t lá»—i:")
            traceback.print_exc()
            return text
    
    def _split_into_sentences(self, text):
        """Split text into sentences"""
        # Split by common sentence delimiters
        sentences = re.split(r'([.!?]\s+)', text)
        
        # Recombine sentences with their delimiters
        result = []
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                result.append(sentences[i] + sentences[i + 1])
            else:
                result.append(sentences[i])
        
        if len(sentences) % 2 == 1:
            result.append(sentences[-1])
        
        # Also split by newlines
        final_result = []
        for sentence in result:
            if '\n' in sentence:
                final_result.extend(sentence.split('\n'))
            else:
                final_result.append(sentence)
        
        return [s.strip() for s in final_result if s.strip()]
    
    def _create_chunks(self, sentences, chunk_size, overlap):
        """Create overlapping chunks from sentences"""
        chunks = []
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_length = len(self.tokenizer.encode(sentence, add_special_tokens=False))
            
            if current_length + sentence_length > chunk_size and current_chunk:
                chunks.append(current_chunk)
                
                # Start new chunk with overlap
                overlap_sentences = current_chunk[-overlap:] if len(current_chunk) > overlap else current_chunk
                current_chunk = overlap_sentences + [sentence]
                current_length = sum(len(self.tokenizer.encode(s, add_special_tokens=False)) for s in current_chunk)
            else:
                current_chunk.append(sentence)
                current_length += sentence_length
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks

# Global instance (lazy loading)
_text_corrector = None

def get_text_corrector(use_gpu=False, model_path="protonx-models/protonx-legal-tc"):
    """Get or create text corrector instance (singleton)"""
    global _text_corrector
    if _text_corrector is None:
        _text_corrector = VietnameseTextCorrector(model_path=model_path, use_gpu=use_gpu)
    return _text_corrector

def correct_vietnamese_text(text, use_correction=True, use_gpu=False):
    """
    Correct Vietnamese text using ProtonX model
    Tá»± Ä‘á»™ng xá»­ lÃ½ text ngáº¯n vÃ  text dÃ i
    
    Args:
        text: Input text (cÃ³ thá»ƒ ráº¥t dÃ i)
        use_correction: Enable/disable correction
        use_gpu: Use GPU if available
        
    Returns:
        Corrected text
    """
    if not use_correction or not text or not text.strip():
        print("âš ï¸  Text correction bá»‹ táº¯t hoáº·c text rá»—ng")
        return text
    
    print(f"\n{'='*60}")
    print("ğŸ”§ Báº®T Äáº¦U Sá»¬A CHÃNH Táº¢ TIáº¾NG VIá»†T")
    print(f"{'='*60}")
    print(f"ğŸ“ Input length: {len(text)} chars")
    print(f"ğŸ“ Input preview: {text[:200]}..." if len(text) > 200 else f"ğŸ“ Input: {text}")
    
    try:
        corrector = get_text_corrector(use_gpu=use_gpu)
        
        if not corrector.initialized:
            print("âš ï¸  Model chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o, Ä‘ang khá»Ÿi táº¡o...")
            corrector._initialize_model()
        
        if not corrector.initialized:
            print("âŒ Model khÃ´ng thá»ƒ khá»Ÿi táº¡o, tráº£ vá» text gá»‘c")
            return text
        
        # Tá»± Ä‘á»™ng chá»n method dá»±a trÃªn Ä‘á»™ dÃ i text
        # Text dÃ i (>1000 chars hoáº·c >500 chars) â†’ dÃ¹ng correct_long_text
        # Text ngáº¯n â†’ dÃ¹ng correct_text
        if len(text) > 1000:
            print("â†’ Text ráº¥t dÃ i (>1000 chars), dÃ¹ng correct_long_text...")
            result = corrector.correct_long_text(text, chunk_size=128)
        elif len(text) > 500:
            print("â†’ Text dÃ i (>500 chars), dÃ¹ng correct_long_text...")
            result = corrector.correct_long_text(text, chunk_size=128)
        else:
            print("â†’ Text ngáº¯n, dÃ¹ng correct_text...")
            result = corrector.correct_text(text, max_length=128)
        
        print(f"\n{'='*60}")
        print(f"âœ… HOÃ€N THÃ€NH Sá»¬A CHÃNH Táº¢")
        print(f"{'='*60}")
        print(f"ğŸ“ Output length: {len(result)} chars")
        print(f"ğŸ“ Output preview: {result[:200]}..." if len(result) > 200 else f"ğŸ“ Output: {result}")
        
        return result
    except Exception as e:
        import traceback
        print(f"\nâŒ Text correction failed: {str(e)}")
        print("ğŸ“‹ Chi tiáº¿t lá»—i:")
        traceback.print_exc()
        return text  # Return original on error

